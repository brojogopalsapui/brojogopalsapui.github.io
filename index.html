<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Brojogopal Sapui</title>
  <meta name="description" content="Brojogopal Sapui — Hardware Security, Side-Channel & Fault Attacks, Secure AI Accelerators, rFET/22nm FDSOI." />
  <link rel="stylesheet" href="assets/css/style.css" />
</head>
<body>
  <header class="site-header">
    <div class="container nav">
      <a class="brand" href="index.html">Brojogopal Sapui</a>
      <nav class="menu">
        <a href="index.html">Home</a>
        <a href="research.html">Research</a>
        <a href="publications.html">Publications</a>
        <a href="projects.html">Projects</a>
        <a href="cv.html">CV</a>
        <a href="contact.html">Contact</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <section class="hero fadeIn">
      <div>
        <h1>Hardware Security & Emerging AI Hardware</h1>
        <p class="lead">
          I work on cross-layer physical security of AI accelerators—side-channel analysis, fault injection,
          and robust countermeasures—spanning FPGA/ASIC accelerators, emerging devices, and security-aware design.
        </p>

        <div class="pill-row">
          <span class="pill">Side-Channel Analysis</span>
          <span class="pill">Fault Injection</span>
          <span class="pill">Secure AI Accelerators</span>
          <span class="pill">rFET / 22nm FDSOI</span>
          <span class="pill">Compute-in-Memory</span>
        </div>

        <div class="cta-row">
          <a class="btn" href="research.html">View Research</a>
          <a class="btn btn-ghost" href="publications.html">Publications</a>
        </div>

        <p class="muted">
          Ph.D., Karlsruhe Institute of Technology (KIT). Starting Feb 2026: NaMLab gGmbH, Dresden.
        </p>
      </div>
    </section>

    <section class="grid">
      <article class="card fadeIn">
        <h2 class="card-title">Research Summary</h2>
        <p>
          My work studies how physical effects (power/EM/timing, voltage droops, device biasing, process corners)
          can leak model information or induce misclassification—and how to design secure, robust accelerators.
        </p>
        <a class="text-link" href="research.html">Read more →</a>
      </article>

      <article class="card fadeIn">
        <h2 class="card-title">Current Themes</h2>
        <ul class="bullets">
          <li>Attacks on AI accelerators (e.g., HDC, NN accelerators)</li>
          <li>Countermeasures: masking, randomization, robust training</li>
          <li>Security-aware device-to-circuit co-design (rFET / back-bias)</li>
        </ul>
      </article>

      <article class="card fadeIn">
        <h2 class="card-title">Selected Projects</h2>
        <ul class="bullets">
          <li>FPGA-based similarity search / Hamming distance engines</li>
          <li>ChipWhisperer-driven fault injection workflows</li>
          <li>Test-chip structures for security characterization</li>
        </ul>
        <a class="text-link" href="projects.html">Browse projects →</a>
      </article>
    </section>

    <footer class="footer">
      <p>© <span id="year"></span> Brojogopal Sapui · Built on GitHub Pages</p>
    </footer>
  </main>

  <script src="assets/js/script.js"></script>
</body>
</html>
